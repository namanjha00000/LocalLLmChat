
# 🌟 Local Open Source LLM Chat App 🌟

Welcome to the Local Open Source LLM Chat App! 🗨️ This app lets you have full control over your conversations while chatting with powerful open-source LLMs—without worrying about your data or privacy. It’s everything you need for a seamless, offline chat experience! 🚀

## 🔥 Features

- **💬 Chat Locally on Open Source LLMs**: Converse with cutting-edge language models directly on your machine. No internet required!
- **🔒 Full Control Over Your Data & Privacy**: Say goodbye to the data privacy concerns of online services. Your data stays local, safe, and secure. 
- **⚡ Always Active**: Even if the internet goes down, your chat never stops. Always available, anytime, anywhere!
- **🗨️ Multiple Chats**: Start as many conversations as you like and easily switch between them.
- **🌐 Chat with Different Open Source LLMs**: Opt-in to connect with various open-source models. Flexibility at its finest!
- **🎨 Friendly & Intuitive UI**: Enjoy a sleek, user-friendly interface designed to make chatting a breeze.
- **📄 Document Upload (Coming Soon)**: Upload documents and discuss them with your LLM.
- **🤖 RAG-based Chat (Coming Soon)**: Power up your chats with Retrieval-Augmented Generation for even more insightful and advanced conversations.

## 🛠️ Setup Instructions

### Prerequisites

Before you dive in, make sure you have Python 3.x installed. Then, clone this repository by using the command:

```bash
git clone https://github.com/namanjha00000/LocalLLmChat.git
cd LocalLLmChat
```
Now if you are a windows user simply run the run.bat script using the following command in the project folder command prompt:
```bash
run.bat
```

For linux/Mac users, run the following command:
```bash
chmod +x run.sh
./run.sh
```

### Enjoy chatting with your own LLM

